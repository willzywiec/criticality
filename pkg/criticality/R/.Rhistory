library(dplyr)
library(ggplot2)
library(magrittr)
library(readr)
library(reticulate)
# set path
# path <- 'C:/Users/Will/Desktop/Test'
path <- 'C:/Users/Will/Desktop/HiMu'
# path <- 'C:/Users/Will/Desktop/MRR'
# path <- 'C:/Users/Will/Desktop/Mega Ray-Ray'
# path <- 'D:/DAF Data/Mega Ray-Ray'
files <- list.files(path = path, pattern = '\\.lmx$', ignore.case = TRUE)
setwd(path)
new.theme <- theme(text = element_text(family = 'serif', size = 11))
theme_set(new.theme)
r1r2 <- c()
for (f in files) {
system(paste0('python -m ldb lmx2csv -o ', gsub('lmx', 'csv', f), ' ', f))
listmode <- read.csv(paste0(path, '/', gsub('.lmx', '.csv', f)), header = FALSE)
names(listmode) <- c('time_s', 'channel')
ggplot(listmode, aes(x = channel)) +
geom_histogram(fill = '#69b3a2', color = '#e9ecef', binwidth = 1, alpha = 0.9)
counts <- listmode %>% count(channel)
counts1 <- counts[1:(round(nrow(counts))/2), ]
counts2 <- counts[(round(nrow(counts))/2):nrow(counts), ]
# calculate Z-scores for each channel
z.score <- (counts$n - mean(counts$n))/sd(counts$n)
# remove channels with Z-scores > 3
for (i in which(abs(z.score) > 3)) {
if (i > 15) {
i <- i + 1
}
sub.listmode <- listmode[listmode$channel != i, ]
listmode <- sub.listmode
}
# recalculate counts
counts <- listmode %>% count(channel)
counts <- counts[order(-counts$n), ]
r1r2 <- append(r1r2, mean(counts1$n)/mean(counts2$n))
# remove first row from 'listmode' to avoid creating a double header
write.csv(listmode[-1, ], file = gsub('.lmx', '.csv', f), row.names = FALSE)
# caculate moments and Y-values and save Feynman data as .csv file
system(paste0(
'python C:/Users/Will/Desktop/HiMu/feynman.py -o ./',
gsub('.lmx', '_feynman.csv', f),
' --logspace ./',
gsub('lmx', 'csv', f), ' -5 0.1 50')) # 1e-5 to 0.1 seconds
# load Feynman data
df <- read.csv(paste0(path, '/', gsub('.lmx', '_feynman.csv', f)))
# strip blank lines and re-save Feynman data
write.csv(df, file = paste0(path, '/', gsub('.lmx', '_feynman.csv', f)), row.names = FALSE)
# perform bunching analysis
for (i in 1:length(df$gate_s)) {
if (df$gate_s[i] > 1e-2) {
system(paste0(
'python C:/Users/Will/Desktop/HiMu/bootstrap-lag1-chatgpt.py -o ./',
gsub('.lmx', paste0('_bs', i, '.csv'), f),
' --bunching ./',
gsub('lmx', 'csv', f), ' ', df$gate_s[i], ' 1'))
# gsub('lmx', 'csv', f), ' 1e-5 1e0 2e0 3e0 4e0 5e0 6e0 7e0 8e0 9e0 1e1 2e1 3e1 4e1 5e1 6e1 7e1 8e1 9e1 1e2 2e2 3e2 4e2 5e2 6e2 7e2 8e2 9e2 1e3 2e3 3e3 4e3 5e3 6e3 7e3 8e3 9e3 1e4 2e4 3e4 4e4 5e4 6e4 7e4 8e4 9e4 1e5')) # first number is fundamental gate width, second through N is the range
}
}
df <- list.files(path=path, pattern=gsub('.lmx', '_bs', f)) %>%
lapply(read.csv) %>%
bind_rows()
write.csv(df, file = paste0(path, '/', gsub('.lmx', '_bootstrap.csv', f)), row.names = FALSE)
unlink(paste0(path, '/*bs*'))
# print file name
cat(f, '\n')
}
library(dplyr)
library(ggplot2)
library(magrittr)
library(readr)
library(reticulate)
# set path
# path <- 'C:/Users/Will/Desktop/Test'
path <- 'C:/Users/Will/Desktop/HiMu'
# path <- 'C:/Users/Will/Desktop/MRR'
# path <- 'C:/Users/Will/Desktop/Mega Ray-Ray'
# path <- 'D:/DAF Data/Mega Ray-Ray'
files <- list.files(path = path, pattern = '\\.lmx$', ignore.case = TRUE)
setwd(path)
new.theme <- theme(text = element_text(family = 'serif', size = 11))
theme_set(new.theme)
r1r2 <- c()
for (f in files) {
system(paste0('python -m ldb lmx2csv -o ', gsub('lmx', 'csv', f), ' ', f))
listmode <- read.csv(paste0(path, '/', gsub('.lmx', '.csv', f)), header = FALSE)
names(listmode) <- c('time_s', 'channel')
ggplot(listmode, aes(x = channel)) +
geom_histogram(fill = '#69b3a2', color = '#e9ecef', binwidth = 1, alpha = 0.9)
counts <- listmode %>% count(channel)
counts1 <- counts[1:(round(nrow(counts))/2), ]
counts2 <- counts[(round(nrow(counts))/2):nrow(counts), ]
# calculate Z-scores for each channel
z.score <- (counts$n - mean(counts$n))/sd(counts$n)
# remove channels with Z-scores > 3
for (i in which(abs(z.score) > 3)) {
if (i > 15) {
i <- i + 1
}
sub.listmode <- listmode[listmode$channel != i, ]
listmode <- sub.listmode
}
# recalculate counts
counts <- listmode %>% count(channel)
counts <- counts[order(-counts$n), ]
r1r2 <- append(r1r2, mean(counts1$n)/mean(counts2$n))
# remove first row from 'listmode' to avoid creating a double header
write.csv(listmode[-1, ], file = gsub('.lmx', '.csv', f), row.names = FALSE)
# caculate moments and Y-values and save Feynman data as .csv file
system(paste0(
'python C:/Users/Will/Desktop/HiMu/feynman.py -o ./',
gsub('.lmx', '_feynman.csv', f),
' --logspace ./',
gsub('lmx', 'csv', f), ' -5 0.1 50')) # 1e-5 to 0.1 seconds
# load Feynman data
df <- read.csv(paste0(path, '/', gsub('.lmx', '_feynman.csv', f)))
# strip blank lines and re-save Feynman data
write.csv(df, file = paste0(path, '/', gsub('.lmx', '_feynman.csv', f)), row.names = FALSE)
# perform bunching analysis
for (i in 1:length(df$gate_s)) {
if (df$gate_s[i] > 1e-2) {
system(paste0(
'python C:/Users/Will/Desktop/HiMu/bootstrap-lag1.py -o ./',
gsub('.lmx', paste0('_bs', i, '.csv'), f),
' --bunching ./',
gsub('lmx', 'csv', f), ' ', df$gate_s[i], ' 1'))
# gsub('lmx', 'csv', f), ' 1e-5 1e0 2e0 3e0 4e0 5e0 6e0 7e0 8e0 9e0 1e1 2e1 3e1 4e1 5e1 6e1 7e1 8e1 9e1 1e2 2e2 3e2 4e2 5e2 6e2 7e2 8e2 9e2 1e3 2e3 3e3 4e3 5e3 6e3 7e3 8e3 9e3 1e4 2e4 3e4 4e4 5e4 6e4 7e4 8e4 9e4 1e5')) # first number is fundamental gate width, second through N is the range
}
}
df <- list.files(path=path, pattern=gsub('.lmx', '_bs', f)) %>%
lapply(read.csv) %>%
bind_rows()
write.csv(df, file = paste0(path, '/', gsub('.lmx', '_bootstrap.csv', f)), row.names = FALSE)
unlink(paste0(path, '/*bs*'))
# print file name
cat(f, '\n')
}
library(dplyr)
library(ggplot2)
library(magrittr)
library(readr)
library(reticulate)
# set path
# path <- 'C:/Users/Will/Desktop/Test'
path <- 'C:/Users/Will/Desktop/HiMu'
# path <- 'C:/Users/Will/Desktop/MRR'
# path <- 'C:/Users/Will/Desktop/Mega Ray-Ray'
# path <- 'D:/DAF Data/Mega Ray-Ray'
files <- list.files(path = path, pattern = '\\.lmx$', ignore.case = TRUE)
setwd(path)
new.theme <- theme(text = element_text(family = 'serif', size = 11))
theme_set(new.theme)
r1r2 <- c()
for (f in files) {
system(paste0('python -m ldb lmx2csv -o ', gsub('lmx', 'csv', f), ' ', f))
listmode <- read.csv(paste0(path, '/', gsub('.lmx', '.csv', f)), header = FALSE)
names(listmode) <- c('time_s', 'channel')
ggplot(listmode, aes(x = channel)) +
geom_histogram(fill = '#69b3a2', color = '#e9ecef', binwidth = 1, alpha = 0.9)
counts <- listmode %>% count(channel)
counts1 <- counts[1:(round(nrow(counts))/2), ]
counts2 <- counts[(round(nrow(counts))/2):nrow(counts), ]
# calculate Z-scores for each channel
z.score <- (counts$n - mean(counts$n))/sd(counts$n)
# remove channels with Z-scores > 3
for (i in which(abs(z.score) > 3)) {
if (i > 15) {
i <- i + 1
}
sub.listmode <- listmode[listmode$channel != i, ]
listmode <- sub.listmode
}
# recalculate counts
counts <- listmode %>% count(channel)
counts <- counts[order(-counts$n), ]
r1r2 <- append(r1r2, mean(counts1$n)/mean(counts2$n))
# remove first row from 'listmode' to avoid creating a double header
write.csv(listmode[-1, ], file = gsub('.lmx', '.csv', f), row.names = FALSE)
# caculate moments and Y-values and save Feynman data as .csv file
system(paste0(
'python C:/Users/Will/Desktop/HiMu/feynman.py -o ./',
gsub('.lmx', '_feynman.csv', f),
' --logspace ./',
gsub('lmx', 'csv', f), ' -5 0.1 50')) # 1e-5 to 0.1 seconds
# load Feynman data
df <- read.csv(paste0(path, '/', gsub('.lmx', '_feynman.csv', f)))
# strip blank lines and re-save Feynman data
write.csv(df, file = paste0(path, '/', gsub('.lmx', '_feynman.csv', f)), row.names = FALSE)
# perform bunching analysis
for (i in 1:length(df$gate_s)) {
if (df$gate_s[i] > 1e-2) {
system(paste0(
'python C:/Users/Will/Desktop/HiMu/bootstrap-lag1-chatgpt.py -o ./',
gsub('.lmx', paste0('_bs', i, '.csv'), f),
' --bunching ./',
gsub('lmx', 'csv', f), ' ', df$gate_s[i], ' 1'))
# gsub('lmx', 'csv', f), ' 1e-5 1e0 2e0 3e0 4e0 5e0 6e0 7e0 8e0 9e0 1e1 2e1 3e1 4e1 5e1 6e1 7e1 8e1 9e1 1e2 2e2 3e2 4e2 5e2 6e2 7e2 8e2 9e2 1e3 2e3 3e3 4e3 5e3 6e3 7e3 8e3 9e3 1e4 2e4 3e4 4e4 5e4 6e4 7e4 8e4 9e4 1e5')) # first number is fundamental gate width, second through N is the range
}
}
df <- list.files(path=path, pattern=gsub('.lmx', '_bs', f)) %>%
lapply(read.csv) %>%
bind_rows()
write.csv(df, file = paste0(path, '/', gsub('.lmx', '_bootstrap.csv', f)), row.names = FALSE)
unlink(paste0(path, '/*bs*'))
# print file name
cat(f, '\n')
}
library(dplyr)
library(ggplot2)
library(magrittr)
library(readr)
library(reticulate)
# set path
# path <- 'C:/Users/Will/Desktop/Test'
path <- 'C:/Users/Will/Desktop/HiMu'
# path <- 'C:/Users/Will/Desktop/MRR'
# path <- 'C:/Users/Will/Desktop/Mega Ray-Ray'
# path <- 'D:/DAF Data/Mega Ray-Ray'
files <- list.files(path = path, pattern = '\\.lmx$', ignore.case = TRUE)
setwd(path)
new.theme <- theme(text = element_text(family = 'serif', size = 11))
theme_set(new.theme)
r1r2 <- c()
for (f in files) {
system(paste0('python -m ldb lmx2csv -o ', gsub('lmx', 'csv', f), ' ', f))
listmode <- read.csv(paste0(path, '/', gsub('.lmx', '.csv', f)), header = FALSE)
names(listmode) <- c('time_s', 'channel')
ggplot(listmode, aes(x = channel)) +
geom_histogram(fill = '#69b3a2', color = '#e9ecef', binwidth = 1, alpha = 0.9)
counts <- listmode %>% count(channel)
counts1 <- counts[1:(round(nrow(counts))/2), ]
counts2 <- counts[(round(nrow(counts))/2):nrow(counts), ]
# calculate Z-scores for each channel
z.score <- (counts$n - mean(counts$n))/sd(counts$n)
# remove channels with Z-scores > 3
for (i in which(abs(z.score) > 3)) {
if (i > 15) {
i <- i + 1
}
sub.listmode <- listmode[listmode$channel != i, ]
listmode <- sub.listmode
}
# recalculate counts
counts <- listmode %>% count(channel)
counts <- counts[order(-counts$n), ]
r1r2 <- append(r1r2, mean(counts1$n)/mean(counts2$n))
# remove first row from 'listmode' to avoid creating a double header
write.csv(listmode[-1, ], file = gsub('.lmx', '.csv', f), row.names = FALSE)
# caculate moments and Y-values and save Feynman data as .csv file
system(paste0(
'python C:/Users/Will/Desktop/HiMu/feynman.py -o ./',
gsub('.lmx', '_feynman.csv', f),
' --logspace ./',
gsub('lmx', 'csv', f), ' -5 0.1 50')) # 1e-5 to 0.1 seconds
# load Feynman data
df <- read.csv(paste0(path, '/', gsub('.lmx', '_feynman.csv', f)))
# strip blank lines and re-save Feynman data
write.csv(df, file = paste0(path, '/', gsub('.lmx', '_feynman.csv', f)), row.names = FALSE)
# perform bunching analysis
for (i in 1:length(df$gate_s)) {
if (df$gate_s[i] > 1e-2) {
system(paste0(
'python C:/Users/Will/Desktop/HiMu/bootstrap-lag1-chatgpt.py -o ./',
gsub('.lmx', paste0('_bs', i, '.csv'), f),
' --bunching ./',
gsub('lmx', 'csv', f), ' ', df$gate_s[i], ' 1'))
# gsub('lmx', 'csv', f), ' 1e-5 1e0 2e0 3e0 4e0 5e0 6e0 7e0 8e0 9e0 1e1 2e1 3e1 4e1 5e1 6e1 7e1 8e1 9e1 1e2 2e2 3e2 4e2 5e2 6e2 7e2 8e2 9e2 1e3 2e3 3e3 4e3 5e3 6e3 7e3 8e3 9e3 1e4 2e4 3e4 4e4 5e4 6e4 7e4 8e4 9e4 1e5')) # first number is fundamental gate width, second through N is the range
}
}
df <- list.files(path=path, pattern=gsub('.lmx', '_bs', f)) %>%
lapply(read.csv) %>%
bind_rows()
write.csv(df, file = paste0(path, '/', gsub('.lmx', '_bootstrap.csv', f)), row.names = FALSE)
unlink(paste0(path, '/*bs*'))
# print file name
cat(f, '\n')
}
install.packages('criticality-torch')
install.packages('torch')
# initialize environment
if (!is.null(dev.list())) dev.off()
rm(list = ls())
cat('\014')
library(curl)
library(devtools)
# install criticality package
install.local = TRUE
if (install.local == TRUE) {
cat('Installing criticality package from local build\n')
# devtools::build('C:/Users/Will/Documents/GitHub/criticality/pkg/criticality')
# devtools::install('C:/Users/Will/Documents/GitHub/criticality/pkg/criticality', upgrade = 'never')
devtools::build('C:/Users/Will/Documents/GitHub/criticality/pkg/criticality-torch')
devtools::install('C:/Users/Will/Documents/GitHub/criticality/pkg/criticality-torch', upgrade = 'never')
} else if (curl::has_internet() == TRUE) {
cat('Installing \'criticality\' from GitHub\n')
# devtools::install_github('willzywiec/criticality/pkg/criticality', dep = FALSE, force = TRUE)
devtools::install_github('willzywiec/criticality/pkg/criticality-torch', dep = FALSE, force = TRUE)
}
# initialize environment
if (!is.null(dev.list())) dev.off()
rm(list = ls())
cat('\014')
library(curl)
library(devtools)
# install criticality package
install.local = TRUE
if (install.local == TRUE) {
cat('Installing criticality package from local build\n')
# devtools::build('C:/Users/Will/Documents/GitHub/criticality/pkg/criticality')
# devtools::install('C:/Users/Will/Documents/GitHub/criticality/pkg/criticality', upgrade = 'never')
devtools::build('C:/Users/Will/Documents/GitHub/criticality-torch/pkg/criticality')
devtools::install('C:/Users/Will/Documents/GitHub/criticality-torch/pkg/criticality', upgrade = 'never')
} else if (curl::has_internet() == TRUE) {
cat('Installing \'criticality\' from GitHub\n')
# devtools::install_github('willzywiec/criticality/pkg/criticality', dep = FALSE, force = TRUE)
devtools::install_github('willzywiec/criticality-torch/pkg/criticality', dep = FALSE, force = TRUE)
}
library(keras)
use_condaenv('base', required=T)
library(tensorflow)
tf$python$client$device_lib$list_local_devices()
# library(keras)
# use_condaenv('base', required=T)
# library(tensorflow)
# tf$python$client$device_lib$list_local_devices()
library(criticality-torch)
# library(keras)
# use_condaenv('base', required=T)
# library(tensorflow)
# tf$python$client$device_lib$list_local_devices()
library(criticality)
# ext.dir <- 'D:/Criticality/Pu'
ext.dir <- 'D:/Criticality/HEU'
# mcnp.output <- read.csv(paste0(ext.dir, '/mcnp-output.csv'))
# summary(mcnp.output)
# tabulate data
dataset = Tabulate(ext.dir = ext.dir)
# build deep neural network metamodel
metamodel <- NN(
dataset = dataset,
ensemble.size = 10,
verbose = TRUE,
ext.dir = ext.dir,
training.dir = paste0(ext.dir, '/training'))
# initialize environment
if (!is.null(dev.list())) dev.off()
rm(list = ls())
cat('\014')
library(devtools)
remove.packages('criticality')
if (Sys.info()[1] == 'Darwin') {
setwd('/Users/will/Documents/GitHub/criticality-torch/pkg/criticality')
} else {
setwd('C:/Users/Will/Documents/GitHub/criticality-torch/pkg/criticality')
}
devtools::document()
# install criticality
devtools::install_github('willzywiec/criticality-torch/pkg/criticality', dep = FALSE)
library(criticality)
library(magrittr)
if (Sys.info()[1] == 'Darwin') {
ext.dir <- '/Users/will/Desktop/extdata'
unlink(ext.dir, recursive = TRUE)
dir.create(ext.dir, recursive = TRUE, showWarnings = FALSE)
file.copy(
'/Users/will/Documents/GitHub/criticality-torch/pkg/criticality/inst/extdata',
'/Users/will/Desktop',
recursive = TRUE) %>% invisible()
} else {
ext.dir <- 'C:/Users/Will/Desktop/extdata'
unlink(ext.dir, recursive = TRUE)
dir.create(ext.dir, recursive = TRUE, showWarnings = FALSE)
file.copy(
'C:/Users/Will/Documents/GitHub/criticality-torch/pkg/criticality/inst/extdata',
'C:/Users/Will/Desktop',
recursive = TRUE) %>% invisible()
}
# rhub::rc_new_token()
rhub::rc_submit(path = '/Users/will/Documents/GitHub/criticality-torch/pkg/criticality', platforms = unlist(rhub::rhub_platforms()[[1]]), email = 'willzywiec@gmail.com')
# initialize environment
if (!is.null(dev.list())) dev.off()
rm(list = ls())
cat('\014')
library(devtools)
remove.packages('criticality')
if (Sys.info()[1] == 'Darwin') {
setwd('/Users/will/Documents/GitHub/criticality-torch/pkg/criticality')
} else {
setwd('C:/Users/Will/Documents/GitHub/criticality-torch/pkg/criticality')
}
devtools::document()
# initialize environment
if (!is.null(dev.list())) dev.off()
rm(list = ls())
cat('\014')
library(devtools)
remove.packages('criticality')
if (Sys.info()[1] == 'Darwin') {
setwd('/Users/will/Documents/GitHub/criticality-torch/pkg/criticality-torch')
} else {
setwd('C:/Users/Will/Documents/GitHub/criticality-torch/pkg/criticality-torch')
}
